# S03.01 MongoDB : Exploration approfondie

L'interrogation de donn√©es est importante.

Mais, si vous connaissez d√©j√† SQL, il est facile, efficace et intelligent de donner le sch√©ma de la base de donn√©es comme contexte de fond √† un LLM (chatGPT, Claude, ...) et de convertir la requ√™te de SQL √† MongoDB.

Ou simplement demander au LLM d'√©crire la requ√™te pour vous. √Ä ce stade, ce qui importe, c'est votre capacit√© √† lire, comprendre et remettre en question les requ√™tes √©crites par le LLM. Pas de les √©crire de z√©ro.

Ce qui est plus important, c'est d'apprendre ce qui caract√©rise r√©ellement MongoDB

- Choisir MongoDB plut√¥t que SQL
- Mod√®les de conception de sch√©ma
- Fonctionnalit√©s sp√©cifiques de MongoDB
- Optimisation des requ√™tes
- Cr√©ation d'index


## SQL vs NoSQL

C'est la premi√®re question √† se poser au d√©but de la conception de votre application.

Nous en avons parl√© la derni√®re fois. Mais il est int√©ressant d'examiner cela plus en d√©tail.

En bref, les bases de donn√©es bas√©es sur des documents ont du sens

*   web scale
*   sch√©ma de donn√©es flexible

> Au fait, il est bien connu que MongoDB est webscale : https://www.youtube.com/watch?v=b2F-DItXtZs

Vous avez d√©pass√© la simple base de donn√©es sqlite ou bas√© sur JSON.

Vers quoi devriez-vous vous tourner ensuite ?

Un excellent article sur quand utiliser NoSQL : <https://medium.com/@sqlinsix/when-to-use-sql-or-nosql-b50d4a52c157> (disponible en pdf dans le repo github)

Extrait :

> NoSQL means not only SQL. With some NoSQL APIs, you may be able to write SQL against them.

> Quelques questions lorsque je compare ces diff√©rents back-ends :

*   √Ä quelle fr√©quence vais-je lire et √©crire les donn√©es ?
*   √Ä quelle fr√©quence la structure des donn√©es va-t-elle changer ?
*   Quelle quantit√© de donn√©es est inconnue ?
*   √Ä quoi ressemble le produit final ?

### L'exemple du workout - les donn√©es sont flexibles

Imaginez une application de gym / workout o√π vous suivez vos s√©ances.

#### La partie SQL

Il y a une s√©rie d'entit√©s compatibles avec une bdd SQL :

- un `user` a plusieurs `sessions`,
- une `gym` a plusieurs `users`,
- un `user` a un `subscription`,
- les `gyms` ont plusieurs `subscriptions` et vice versa.

Donc la gestion des abonnements convient bien a une bdd relationnelle / SQL.

Les donn√©es √©voluent peu et la dimension transactions sont importantes

#### La partie NoSQL : document

Mais il y a aussi une entit√© **workout** qui, par nature, peut varier  beaucoup.

- poids et r√©p√©titions : dead lifts, clean and jerks, ...
- sans poids : dead lifts, clean and jerks, ...
- course, rowing, natation, ...
- v√©los, marches, sauts en parachute, ...
- power yoga, pilates, Zumba, ...

Un sch√©ma de donn√©es fixe n'est pas adapt√©.

Autre extrait du m√™me article :

> "_La complexit√© des jointures serait √©norme par rapport √† l'entra√Ænement d'une personne, car il peut y avoir des dizaines de combinaisons. De plus, les entra√Ænements tels que les s√©ries d√©gressives o√π le poids change constamment et o√π une plage de r√©p√©titions maximale (ou minimale) doit √™tre respect√©e seraient extr√™mement difficiles √† suivre avec un sch√©ma fixe pour une base SQL._"

Une application exploitant les donn√©es des workouts est un bon exemple o√π une structure de donn√©es √† **sch√©ma flexible** a vraiment du sens.

Il faut r√©fl√©chir √† la mani√®re dont l'application consomme les donn√©es.

Par exemple si l'application r√©cup√©re l'int√©gralit√© d'un entra√Ænement pour un jour donn√©.

Dans une base SQL normalis√©e (une info existe dans une table unique) nous aurions besoin de faire un nombre de jointure important entre la table ed `session` et celles des diff√©rents type d'`exercices` et du workout du jour.

Avec une bdd NoSQL de type document (MongoDB), comme l'entit√©  workout est stock√©e dans son int√©gralit√© comme une seule information, dans un seul document, il n'y a plus besoin de ces jointures entre plusieurs tables.

Note : PostgreSQL dispose d√©sormais de types de donn√©es JSON qui peuvent √™tre utilis√©s pour un tel cas de donn√©es polymorphes.

### Polymorphisme des donn√©es

Des donn√©es dont les champs varient fortement seront plus adapt√©es √† une bdd NoSQL-document, quand l'application finale s'en sert.

Par contre des donn√©es stables, qui √©voluent peu seront plus adapt√©es √† une bdd SQL classique.

## ACID:

ACID est un ensemble de propri√©t√©s garantissant la fiabilit√© des transactions dans une base de donn√©es :

1. **Atomicit√© (Atomicity)** : Une transaction est enti√®rement ex√©cut√©e ou annul√©e en cas d‚Äô√©chec (tout ou rien).
2. **Coh√©rence (Consistency)** : Une transaction am√®ne la base d‚Äôun √©tat valide √† un autre √©tat valide, respectant les contraintes d‚Äôint√©grit√©.
3. **Isolation (Isolation)** : Les transactions concurrentes s‚Äôex√©cutent sans interf√©rer entre elles, comme si elles √©taient ex√©cut√©es s√©quentiellement.
4. **Durabilit√© (Durability)** : Une fois valid√©e, une transaction est d√©finitivement enregistr√©e, m√™me en cas de panne.

Ces propri√©t√©s sont essentielles pour assurer l‚Äôint√©grit√© des donn√©es dans les bases relationnelles et certaines bases NoSQL. üöÄ


| **Crit√®re**                      | **PostgreSQL**       | **MongoDB**                    |
| -------------------------------- | -------------------- | ------------------------------ |
| **ACID natif ?**                 | ‚úÖ Oui (complet)      | ‚ö†Ô∏è Partiel (multi-docs co√ªteux) |
| **Transactions multi-documents** | ‚úÖ Oui et optimis√©es  | ‚ö†Ô∏è Oui mais co√ªteuses           |
| **Isolation forte**              | ‚úÖ Oui (SERIALIZABLE) | ‚ö†Ô∏è Pas aussi strict             |
| **Scalabilit√©**                  | ‚ö†Ô∏è Moins flexible     | ‚úÖ Plus souple pour big data    |


- üöÄ PostgreSQL est plus fiable pour les transactions critiques, notamment bancaires ou financi√®res.
- ‚ö° MongoDB est utile pour des bases scalables, mais ACID y est plus co√ªteux et moins robuste que PostgreSQL.


### **MongoDB est-il moins fiable pour ACID que PostgreSQL ?**

üëâ **Oui, MongoDB est moins strict que PostgreSQL en mati√®re d'ACID**, notamment pour les transactions multi-documents et l‚Äôisolation concurrentielle.


### **üìå Exemple : Probl√®me de coh√©rence des transactions multi-documents**

#### **Cas d‚Äôune base bancaire : Transfert d‚Äôargent entre deux comptes**

Imaginez que vous ayez une base de donn√©es avec deux collections :
- **`accounts`** (stocke les comptes bancaires avec `balance`)
- **`transactions`** (stocke l‚Äôhistorique des transferts)

#### **PostgreSQL (ACID robuste)**
```sql
BEGIN;

UPDATE accounts
SET balance = balance - 500
WHERE account_id = 1;

UPDATE accounts
SET balance = balance + 500
WHERE account_id = 2;

INSERT INTO transactions (from_account, to_account, amount)
VALUES (1, 2, 500);

COMMIT;
```

‚úÖ **Si une des op√©rations √©choue**, tout est annul√© (`ROLLBACK` automatique).
‚úÖ **Les autres transactions concurrentes ne verront pas d‚Äô√©tat interm√©diaire**.

---

#### **MongoDB (Risque avec transactions multi-documents)**

```javascript
const session = db.getMongo().startSession();
session.startTransaction();

try {
  // D√©biter 500‚Ç¨ du compte 1
  session.getDatabase("bank").accounts.updateOne(
    { account_id: 1 },
    { $inc: { balance: -500 } }
  );

  // Cr√©diter 500‚Ç¨ au compte 2
  session.getDatabase("bank").accounts.updateOne(
    { account_id: 2 },
    { $inc: { balance: 500 } }
  );

  // Ajouter un enregistrement de transaction
  session.getDatabase("bank").transactions.insertOne(
    { from: 1, to: 2, amount: 500, timestamp: new Date() }
  );

  session.commitTransaction();
} catch (error) {
  session.abortTransaction();
}
session.endSession();
```

### **üö® Probl√®me potentiel avec MongoDB :**

- Avant **MongoDB 4.0**, **chaque op√©ration √©tait ind√©pendante**, donc si une mise √† jour √©chouait, l‚Äôautre pouvait √™tre appliqu√©e, cr√©ant **un √©tat incoh√©rent**.
- **Les transactions multi-documents existent**, mais sont **plus co√ªteuses en performance et moins optimis√©es que PostgreSQL**.
- **Si le serveur tombe apr√®s la mise √† jour d‚Äôun document mais avant l‚Äôautre**, **la base peut √™tre corrompue**.
- **MongoDB n‚Äôa pas de niveaux d‚Äôisolation avanc√©s** comme **SERIALIZABLE** en PostgreSQL.



### **üîé Conclusion**
| **Crit√®re**                      | **PostgreSQL**       | **MongoDB**                    |
| -------------------------------- | -------------------- | ------------------------------ |
| **ACID natif ?**                 | ‚úÖ Oui (complet)      | ‚ö†Ô∏è Partiel (multi-docs co√ªteux) |
| **Transactions multi-documents** | ‚úÖ Oui et optimis√©es  | ‚ö†Ô∏è Oui mais co√ªteuses           |
| **Isolation forte**              | ‚úÖ Oui (SERIALIZABLE) | ‚ö†Ô∏è Pas aussi strict             |
| **Scalabilit√©**                  | ‚ö†Ô∏è Moins flexible     | ‚úÖ Plus souple pour big data    |

üöÄ **PostgreSQL** est **plus fiable pour les transactions critiques**, notamment **bancaires ou financi√®res**.
‚ö° **MongoDB** est utile pour des bases **scalables**, mais **ACID y est plus co√ªteux et moins robuste** que PostgreSQL.

### OLTP vs OLAP

Avez vous besoin d'une base OLAP ou OLTP ?

Et dans quel cas une bdd de type MongoDB sera-t-elle plus adapt√©e qu'une bdd SQL ?

On consid√®re 2 principaux types d'utilisation des bases de donn√©es : transactions ou tableaux de bord

#### OLTP

D'un cot√©, les syst√®mes **OLTP** (Online Transaction Processing) se concentrent sur la gestion d'un grand nombre de transactions courtes et atomiques en temps r√©el. Ils sont optimis√©s pour les op√©rations d'√©criture et l'int√©grit√© transactionnelle, couramment utilis√©s pour des applications telles que le commerce √©lectronique, la banque et la gestion des stocks.

Dans les syst√®mes OLTP, on optimise au maximum la fiabilit√© des √©critures, l'int√©grit√© des donn√©es et la normalisation de la base.

Pensez OLTP ~= transactions.

#### OLAP

D'un autre cot√©, les syst√®mes **OLAP** (Online Analytical Processing) sont con√ßus pour interroger et analyser de grands volumes de donn√©es, impliquant souvent des jointures complexes, des agr√©gations et des transformations de donn√©es.

Ces syst√®mes sont _intensifs en lecture_ et n√©cessitent une r√©cup√©ration de donn√©es optimis√©e. La d√©normalisation simplifie les requ√™tes et am√©liore les performances.

Pensez OLAP ~= tableaux de bord.

Donc, la grande question est la suivante: _doit-on utiliser NoSQL ou SQL pour OLAP ? pour OLTP ?_

- Pour les applications OLTP : Le cot√© document de MongoDB est parfait pour la gestion de nombreuses transactions petites et rapides, car chaque document contient toutes les donn√©es.

- Pour les applications OLAP : MongoDB pr√©sente certaines limitations qui le rendent moins id√©al pour les requ√™tes analytiques complexes :

  - Le pipeline d'agr√©gation (utilis√© pour les requetes complexes) est puissant, mais il peut devenir assez complexe pour des requ√™tes a vis√©es analytiques, par essence  compliqu√©es. Un  sch√©ma SQL fixe et normalis√© pourrait √™tre plus simple.
  - En MongoDB, joindre de grandes quantit√©s de donn√©es appartenant √† diff√©rentes collections sera gourmand en m√©moire et plus lent en comparaison avec des bases de donn√©es SQL.
  - Le moteur de stockage de MongoDB est optimis√© pour les sch√©mas d'acc√®s al√©atoires (typiques de l'OLTP) quand les index ad√©quats auront √©t√© cr√©√© au pr√©alable, plut√¥t que pour les analyses s√©quentielles courantes dans les charges de travail analytiques. .


MongoDB, en tant que base de donn√©es NoSQL orient√©e document, est optimis√©e pour des op√©rations de lecture et d'√©criture rapides sur des documents individuels, ce qui est id√©al pour les applications OLTP.


Cependant

Pour des applications OLTP au sens strict du terme on choisira une base SQL car plus ACID que MongoDB



Donc

OLTP: Focuses on managing real-time transactional data, emphasizing speed and accuracy for operations like order processing, inventory management, and financial transactions.

OLAP: Centers on complex data analysis and reporting, handling large volumes of historical data to support decision-making processes.




## [EXERCICE] questionner un LLM

**Sc√©nario** : si vous transf√©rez la charge de travail des jointures et de l'agr√©gation au niveau de la collection (par le biais de t√¢ches d'arri√®re-plan r√©guli√®res par exemple), alors une bdd  documents tel que MongoDB devient-il comp√©titif pour les applications OLAP ?

- Demander √† un LLM (chatGPT, DeepSeek, Claude.ai, Qwen, Mistral, ) ce qu'il en pense.
- Comparer les reponses 2 √† 2
- quels sont les arguments avanc√©s ?
- demander au LLM d'argumenter pour cette solution

## Cas plus adapt√©s a MongoDB

beyond OLTP / OLAP

MongoDB is particularly well-suited for applications that require flexibility, scalability, and the ability to handle diverse and evolving data types.


- Content Management Systems (CMS)
MongoDB's flexible schema allows for the storage and retrieval of various content types, making it ideal for CMS platforms that manage diverse media and documents.


- Internet of Things (IoT)
With its ability to handle large volumes of unstructured data, MongoDB is well-suited for IoT applications that collect and process data from numerous devices.


- Mobile Applications
Its flexible data model and support for offline data synchronization make MongoDB a strong choice for mobile applications that require seamless data handling across devices.


- E-commerce Platforms
MongoDB's scalability and ability to handle diverse product catalogs and customer data make it suitable for e-commerce platforms that need to manage large inventories and user interactions.



### Morale de l'histoire

Cette phrase met en lumi√®re quand utiliser NoSQL

extrait de : https://softwareengineering.stackexchange.com/a/355964/440337

> _NOSQL is very much designed as a persistence layer for an application_
> _So access is optimized for a single object with children._

en VF

> _NOSQL est tr√®s largement con√ßu comme une couche de persistance pour une application._
> _L'acc√®s est donc optimis√© pour un seul objet avec des enfants._



Beaucoup de choses √† d√©cortiquer ici :

- **couche de persistance** fait r√©f√©rence au stockage et √† la r√©cup√©ration de donn√©es afin qu'elles survivent au-del√† de la dur√©e d'ex√©cution de l'application.

Les bases de donn√©es NoSQL (Document) sont construites sp√©cifiquement pour r√©pondre aux besoins de **stockage de donn√©es** des applications. Le mot important √©tant "Application".

En comparaison, les bases de donn√©es SQL sont con√ßues pour l'organisation et les relations de donn√©es, mais les besoins des applications √©tant secondaires.

- Un **seul objet** fait r√©f√©rence √† une entit√© de donn√©es principale (comme un profil d'utilisateur, un produit, une playlist ou un workout)

- Les children ou **enfants** font r√©f√©rence aux donn√©es associ√©es qui appartiennent ou sont √©troitement associ√©es √† cet objet principal (comme les adresses d'un utilisateur, les avis sur un produit ou les exercices d'un workout)

Pourquoi est-ce optimis√© pour un  _objet unique_ avec des _enfants_ ?

**unique** est un mot important ici :

Les bases de donn√©es NoSQL stockent physiquement l'objet principal et ses sous d√©pendants ensemble dans un **emplacement unique** sur le disque. Au lieu de diviser les donn√©es associ√©es sur plusieurs tables comme dans les bases de donn√©es relationnelles.

La r√©cup√©ration de toutes les donn√©es associ√©es n√©cessite moins d'op√©rations sur le disque et est moins gourmande en ressources et donc plus rapide.

Ce qui implique √©galement un principe architectural cl√© : les bases de donn√©es NoSQL sont con√ßues autour des mani√®res sp√©cifiques dont les applications ont besoin d'acc√©der aux donn√©es, plut√¥t que de maintenir des relations formelles de donn√©es .

Besoin de l'application > Organisation structur√©e des donn√©es

Cela les rend particuli√®rement efficaces lorsqu'une application a besoin de rapidement r√©cup√©rer / mettre √† jour  un objet entier avec toutes ses donn√©es associ√©es et ceci en une seule op√©ration.

## Recapitulons

NoSQL / document quand

- donn√©es √©volutives avec une structure qui peut changer: schema flexible
- les donn√©es et sous donn√©es associ√©es sont consomm√©es d'un coup par l'application


SQL quand
- OLTP ou OLAP classique
- donn√©es avec un sch√©ma fixe
- ACID compliance



## Performance d'une bdd NoSQL

Plusieurs facteurs techniques peuvent affecter les performances :

- **Indexation :** Tout d'abord, les bases de donn√©es NoSQL ne maintiennent pas le m√™me type d'index sophistiqu√©s que les bases de donn√©es relationnelles pour joindre les donn√©es r√©parties dans diff√©rentes collections. Le r√¥le des index dans MongoDB est d'**aider √† localiser** des documents individuels plutot que d'optimiser les requ√™tes complexes sur plusieurs documents.

- **Acc√®s disque :** Ensuite, lorsque vous devez acc√©der √† plusieurs objets qui ne sont pas physiquement stock√©s √† proximit√© les uns des autres, la base de donn√©es doit effectuer plusieurs recherches al√©atoires sur le disque.

Ces recherches al√©atoires sont beaucoup plus lentes que les lectures s√©quentielles, car la t√™te de lecture du disque doit se d√©placer physiquement vers diff√©rents emplacements. C'est pourquoi les op√©rations qui n√©cessitent l'analyse de nombreux documents (comme les requ√™tes analytiques) peuvent √™tre plus lentes dans MongoDB que dans les bases de donn√©es relationnelles.

- **Gestion de la m√©moire :** Enfin, la gestion de la m√©moire de MongoDB est optimis√©e autour du concept d'ensembles de travail (working sets) :  les documents qui sont le plus fr√©quemment consult√©s. Sur de grands volumes de donn√©es qui d√©passent la taille de la RAM, MongoDB doit constamment √©changer des documents en dedans et en dehors de la m√©moire avec  un impact probable sur les performances.

Sur le point 2, d'Acc√®s disque : Le probl√®me de donn√©es r√©parties un peu partout sur le disque physique √† des emplacements al√©atoires est vrai pour toutes les bases de donn√©es.

Mais PostgreSQL (par exemple) est beaucoup plus optimis√©e pour ce genre de t√¢ches que ne l'est MongoDB.



Il existe des diff√©rences architecturales cl√©s dans la mani√®re dont les deux bases de donn√©es g√®rent les op√©rations multi-enregistrements :

- Disposition du stockage : meilleure organisation du stockage et plus de contraintes dans PostgreSQL

  - PostgreSQL stocke les donn√©es dans des tables avec des sch√©mas fixes, en utilisant un concept appel√© "fichiers heap" o√π les enregistrements sont stock√©s dans des blocs/pages. Ces pages sont con√ßues pour un balayage s√©quentiel efficace.

  - MongoDB stocke chaque document ind√©pendamment, potentiellement avec des tailles et des sch√©mas variables. Cela peut conduire √† plus de fragmentation et √† un acc√®s s√©quentiel moins efficace.

- M√©thodes d'acc√®s aux donn√©es : meilleure planification des requ√™tes

  - PostgreSQL a une planification de requ√™tes tr√®s sophistiqu√©e  et donc tr√®s efficace qui choisi entre plusieurs m√©thodes d'acc√®s :
    - Des analyses s√©quentielles (Sequential scans) qui lisent les pages efficacement dans l'ordre
    - Des analyses d'index (Index scans) qui peuvent utiliser plusieurs index simultan√©ment
    - Des analyses bitmap (Bitmap scans) qui peuvent combiner les r√©sultats de plusieurs type d'index
  - MongoDB s'appuie principalement sur des analyses d'index unique (single-index scans) ou des analyses de collection (collection scans), avec moins de facult√©es pour combiner les m√©thodes d'acc√®s

- Op√©rations de jointure :
  - PostgreSQL dispose d'algorithmes sp√©cialis√©s (jointures hach√©es, jointures par fusion, boucles imbriqu√©es) - (hash joins, merge joins, nested loops) - qui sont optimis√©s pour combiner efficacement les donn√©es de plusieurs tables
  - MongoDB doit effectuer des recherches un document √† la fois lors de la combinaison de donn√©es entre les collections, ce qui signifie souvent plus d'E/S al√©atoires

- Gestion des buffers :
  - Le gestionnaire de buffer de PostgreSQL est con√ßu pour optimiser les sch√©mas d'acc√®s s√©quentiels et al√©atoires
  - Le moteur de stockage WiredTiger de MongoDB est principalement optimis√© pour les sch√©mas d'acc√®s al√©atoires

Ainsi, bien que les deux bases de donn√©es doivent effectuer des op√©rations sur disque, PostgreSQL inclut des optimisations sp√©cifiques pour g√©rer efficacement les op√©rations multi-enregistrements, en particulier lorsqu'il s'agit de jointures et d'analyses de grandes tables.

Ces optimisations sont moins pr√©sentes dans MongoDB car son architecture donne la priorit√© aux op√©rations sur un seul document.

### Conclusion sur SQL vs NoSQL - PostgreSQL vs MongoDB

**Impossible d'√©chapper √† la complexit√©.**

La vitesse n'est pas le seul facteur √† prendre en compte lors du choix d'une base de donn√©es.

Ind√©pendamment de toute consid√©ration technique, la disponibilit√© et la productivit√© des ing√©nieurs ont plus d'impact sur les co√ªts que quelques millisecondes gagn√©es sur une requete.

Ce qui motive l'adoption de MongoDB par rapport √† PostgreSQL est

- Comment l'application consomme les donn√©es
- le stockage et la r√©cup√©ration d'enregistrements uniques
- la complexit√© des donn√©es

## Performance

### Comparaison des performances PostgreSQL vs MongoDB

Lisez cet article <https://medium.com/@vosarat1995/postgres-vs-mongo-performance-comparison-for-semi-structured-data-9a5ec6486cf6>

L'auteur cr√©e un grand jeux de donn√©es et teste les performances de MongoDB et de PostgreSQL.

```bash
| Test                                          | Mongo     | PostgreSQL |
| --------------------------------------------- | --------- | ---------- |
| Cr√©ation d'index sur une base de donn√©es vide | 152.9 ms  | 402.0 ms   |
| Insertion par lot                             | 53.50 ms  | 219.15 ms  |
| Insertion un par un                           | 319.3 ms  | 641.9 ms   |
| Lecture de plusieurs enregistrements          | 21.83 ms  | 66.63 ms   |
| Cr√©ation d'index sur 1000 rows                | 1.563 s   | 1.916 s    |
| Requ√™te Complexe                              | 174.51 ms | 60.43 ms   |
```

MongoDB gagne la plupart du temps.

Mais PostgreSQL gagne au sprint final!

De plus : "_It is worth noting that the tests were on semi-structured data which is the realm of Mongo._"

### Explication de la planification des requ√™tes dans MongoDB

Sans entrer pour l'instant dans les d√©tails de creation des index avec MongoDB analysons la planification des requ√™tes.

Pour `EXPLAIN` une requ√™te:

- requ√™te directe : `db.movies.find(<query predicate>).explain("executionStats")`
- pipelines d'agr√©gation : `db.movies.explain("executionStats").aggregate(<the_pipeline>)`

Notez les √©l√©ments suivants

- `totalDocsExamined`
- `nReturned`
- `executionTimeMillisEstimate` : estime le temps d'ex√©cution cumulatif pour le pipeline jusqu'√† l'√©tape en question incluse.
- `rejectedPlans`
- `stage` : COLLSCAN, IXSCAN

comparez : `db.movies.find({ "title": "The Perils of Pauline" }).explain("executionStats")`

Ensuite, cr√©ez un index `db.movies.createIndex({ title: 1 })`

√† nouveau `db.movies.find({ "title": "The Perils of Pauline" }).explain("executionStats")`

Supprimez l'index `db.movies.dropIndex({title : 1})`

Expliquez un pipeline d'agr√©gation `db.movies.explain("executionStats").aggregate([ { $group: { _id: "$genres", averageRating: { $avg: "$imdb.rating" } } }] )`

### Comparaison de la planification des requ√™tes avec PostgreSQL

Consid√©rez un sc√©nario de requ√™tes similaires qui implique de joindre/relier des donn√©es et d'agr√©ger des r√©sultats.

**Requ√™te** : _trouver tous les films des ann√©es 1990 avec leurs r√©alisateurs, regroup√©s par r√©alisateur avec les notes moyennes._

Tout d'abord, MongoDB :

```bash
db.movies.aggregate([
  { $match: {
      year: { $gte: 1990, $lt: 2000 }
  }},
  { $unwind: "$directors" },
  { $group: {
      _id: "$directors",
      avgRating: { $avg: "$imdb.rating" },
      movieCount: { $sum: 1 }
  }}
]).explain("executionStats")
```


Le plan est:

```json
{
  "stages": [
    {
      "$cursor": {
        "queryPlanner": {
          "plannerVersion": 1,
          "namespace": "sample_mflix.movies",
          "indexFilterSet": false,
          "parsedQuery": {
            "year": { "$gte": 1990, "$lt": 2000 }
          },
          "winningPlan": {
            "stage": "COLLSCAN",  // Analyse compl√®te de la collection
            "filter": { "year": { "$gte": 1990, "$lt": 2000 } }
          },
          "rejectedPlans": []
        }
      }
    },
    { "$unwind": "$directors" },  // Op√©ration gourmande en m√©moire
    {
      "$group": {
        "_id": "$directors",
        "avgRating": { "$avg": "$imdb.rating" },
        "movieCount": { "$sum": 1 }
      }
    }
  ]
}
```

Maintenant, l'√©quivalent en PostgreSQL (en supposant un sch√©ma normalis√©) :

```sql
EXPLAIN ANALYZE
SELECT d.name as director,
  AVG(m.rating) as avg_rating,
  COUNT(*) as movie_count
FROM movies m
JOIN movie_directors md ON m.id = md.movie_id
JOIN directors d ON md.director_id = d.id
WHERE m.year >= 1990 AND m.year < 2000
GROUP BY d.name;
```

Ce qui donne :

```bash
QUERY PLAN
------------------------------------------------------------
HashAggregate  (cost=245.97..247.97 rows=200)
  Group Key: d.name
  ->  Hash Join  (cost=121.67..237.42 rows=1710)
        Hash Cond: (md.director_id = d.id)
        ->  Hash Join  (cost=66.50..164.42 rows=1710)
              Hash Cond: (md.movie_id = m.id)
              ->  Seq Scan on movie_directors md
              ->  Hash  (cost=58.00..58.00 rows=680)
                    ->  Index Scan using movies_year_idx on movies m
                          Index Cond: (year >= 1990 AND year < 2000)
        ->  Hash  (cost=40.50..40.50 rows=1173)
              ->  Seq Scan on directors d
```

Les principales diff√©rences dans la planification des requ√™tes sont :

1. Gestion des jointures¬†:
   - PostgreSQL utilise des **jointures hach√©es** (**hash joins**) pour combiner efficacement les donn√©es de plusieurs tables
   - MongoDB doit `$unwind` le tableau imbriqu√© des r√©alisateurs, ce qui cr√©e plusieurs documents en m√©moire

2. Utilisation de l'index¬†:
   - PostgreSQL peut utiliser **plusieurs index** simultan√©ment et choisir diff√©rentes strat√©gies de jointure
   - MongoDB s'appuie g√©n√©ralement sur un seul index par √©tape de l'agr√©gation

3. Gestion de la m√©moire¬†:
   - Les jointures hach√©es de PostgreSQL cr√©ent des tables de hash en m√©moire avec repli  disque si n√©cessaire
   - Les √©tapes `$unwind` et `$group` de MongoDB doivent conserver leurs donn√©es en m√©moire

4. Ordre des op√©rations¬†:
   - Le planificateur de requ√™tes de PostgreSQL peut **r√©organiser les op√©rations** pour plus d'efficacit√©
   - MongoDB doit traiter les √©tapes du pipeline d'agr√©gation dans l'ordre

5. Utilisation des statistiques¬†:
   - L'explication de PostgreSQL montre des estimations de co√ªt d√©taill√©es bas√©es sur les statistiques de la table
   - L'explication de MongoDB se concentre davantage sur le type d'op√©ration et l'utilisation de l'index

Le plan PostgreSQL montre qu'il peut¬†:

- Utiliser une analyse d'index pour le filtre d'ann√©e
- Cr√©er des tables de hachage pour une jointure efficace
- Effectuer un regroupement avec agr√©gation hach√©e
- Estimer les co√ªts et le nombre de lignes √† chaque √©tape

üëΩüëΩüëΩ Cette approche structur√©e des requ√™tes complexes est la raison pour laquelle PostgreSQL est souvent plus performant pour les charges de travail analytiques impliquant plusieurs tables/collections et agr√©gations.


