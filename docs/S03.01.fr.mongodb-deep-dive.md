# S02.04 MongoDB : Exploration approfondie

L'interrogation de donn√©es est importante.

Mais, si vous connaissez d√©j√† SQL, il est facile, efficace et intelligent de donner le sch√©ma de la base de donn√©es comme contexte de fond √† un LLM (chatGPT, Claude, ...) et de convertir la requ√™te de SQL √† MongoDB.

Ou simplement demander au LLM d'√©crire la requ√™te pour vous. √Ä ce stade, ce qui importe, c'est votre capacit√© √† lire, comprendre et remettre en question les requ√™tes √©crites par le LLM. Pas de les √©crire de z√©ro.

Ce qui est plus important, c'est d'apprendre ce qui caract√©rise r√©ellement MongoDB

- Choisir MongoDB plut√¥t que SQL
- Mod√®les de conception de sch√©ma
- Fonctionnalit√©s sp√©cifiques de MongoDB
- Optimisation des requ√™tes
- Cr√©ation d'index


## SQL vs NoSQL

C'est la premi√®re question √† se poser au d√©but de la conception de votre application.

Nous en avons parl√© la derni√®re fois. Mais il est int√©ressant d'examiner cela plus en d√©tail.

En bref, les bases de donn√©es bas√©es sur des documents ont du sens

*   web scale
*   sch√©ma de donn√©es flexible

> Au fait, il est bien connu que MongoDB est webscale : https://www.youtube.com/watch?v=b2F-DItXtZs

Vous avez d√©pass√© le simple magasin de donn√©es sqlite ou bas√© sur JSON.

Vers quoi devriez-vous vous tourner ensuite ?

Un excellent article sur quand utiliser NoSQL : <https://medium.com/@sqlinsix/when-to-use-sql-or-nosql-b50d4a52c157> (disponible en pdf dans le repo github)

Extrait :

> Quelques questions lorsque je compare ces diff√©rents back-ends :

*   √Ä quelle fr√©quence vais-je lire et √©crire les donn√©es ?
*   √Ä quelle fr√©quence la structure des donn√©es va-t-elle changer ?
*   Quelle quantit√© de donn√©es est inconnue ?
*   √Ä quoi ressemble le produit final ?


### L'exemple du workout - les donn√©es sont flexibles

Imaginez une application de workout o√π vous suivez vos s√©ances.

Il y a une s√©rie d'entit√©s compatibles avec une bdd SQL :

- un `user` a plusieurs `sessions`,
- une `gym` a plusieurs `users`,
- un `user` a un `subscription`,
- les `gyms` ont plusieurs `subscriptions` et vice versa.

Mais il y a aussi une entit√© **workout** qui, par nature, peut varier  beaucoup.

- poids et r√©p√©titions : dead lifts, clean and jerks, ...
- sans poids : dead lifts, clean and jerks, ...
- course, rowing, natation, ...
- v√©los, marches, sauts en parachute, ...
- power yoga, pilates, Zumba, ...

Un sch√©ma de donn√©es fixe n'est pas adapt√©.

Autre extrait du m√™me article :

> "_La complexit√© des jointures serait √©norme par rapport √† l'entra√Ænement d'une personne, car il peut y avoir des dizaines de combinaisons. De plus, les entra√Ænements tels que les s√©ries d√©gressives o√π le poids change constamment et o√π une plage de r√©p√©titions maximale (ou minimale) doit √™tre respect√©e seraient extr√™mement difficiles √† suivre avec un sch√©ma fixe pour une base SQL._"

L'application des workouts sont un bon exemple o√π une structure de donn√©es √† **sch√©ma flexible** a vraiment du sens.

Il faut surtout r√©fl√©chir √† la mani√®re dont l'application consomme les donn√©es.

Par exemple si l'on souhaite enregistrer ou r√©cup√©rer l'int√©gralit√© d'un entra√Ænement pour un jour donn√©.

Dans une base SQL normalis√©e (une info existe dans une table unique) nous aurions besoin de faire un nombre de jointure important entre la table ed `session` et celles des diff√©rents type d'`exercices` et du workout du jour.

Avec une bdd NoSQL de type document (MongoDB), comme l'entit√©  workout est stock√©e dans son int√©gralit√© comme une seule information, dans un seul document, il n'y a plus besoin de ces jointures entre plusieurs tables.

Note : PostgreSQL dispose d√©sormais de types de donn√©es JSON qui peuvent √™tre utilis√©s pour un tel cas de donn√©es polymorphes.

### OLTP vs OLAP

Avez vous  besoin d'une base OLAP ou OLTP ?

Et dans quel cas une bdd de type MongoDB serra t elle plus adapt√©e que une bdd SQL ?

On consid√®re 2 principaux types d'utilisation des bases de donn√©es : transactions ou tableaux de bord

#### OLTP

D'un cot√©, les syst√®mes **OLTP** (Online Transaction Processing) se concentrent sur la gestion d'un grand nombre de transactions courtes et atomiques en temps r√©el. Ils sont optimis√©s pour les op√©rations d'√©criture et l'int√©grit√© transactionnelle, couramment utilis√©s pour des applications telles que le commerce √©lectronique, la banque et la gestion des stocks.

Dans les syst√®mes OLTP, on optimise au maximum la fiabilit√© des √©critures, l'int√©grit√© des donn√©es et la normalisation de la base.

Pensez OLAP ~= transactions.

#### OLAP

D'un autre cot√©, les syst√®mes **OLAP** (Online Analytical Processing) sont con√ßus pour interroger et analyser de grands volumes de donn√©es, impliquant souvent des jointures complexes, des agr√©gations et des transformations de donn√©es.

Ces syst√®mes sont _intensifs en lecture_ et n√©cessitent une r√©cup√©ration de donn√©es optimis√©e. La d√©normalisation simplifie les requ√™tes et am√©liore les performances.

Pensez OLAP ~= tableaux de bord.

Donc, la grande question est la suivante: _doit-on utiliser NoSQL ou SQL pour OLAP ? pour OLTP ?_

- Pour les applications OLTP : Le cot√© document de MongoDB est parfait pour la gestion de nombreuses transactions petites et rapides, car chaque document contient toutes les donn√©es.

- Pour les applications OLAP : MongoDB pr√©sente certaines limitations qui le rendent moins id√©al pour les requ√™tes analytiques complexes :

  - Le pipeline d'agr√©gation (utilis√© pour les requetes complexes) est puissant, mais il peut devenir assez complexe pour des requ√™tes a vis√©es analytiques, par essence  compliqu√©es. Un  sch√©ma SQL fixe et normalis√© pourrait √™tre plus simple.
  - En MongoDB, joindre de grandes quantit√©s de donn√©es appartenant √† diff√©rentes collections sera gourmand en m√©moire et plus lent si' l'on compare avec des bases de donn√©es SQL.
  - Le moteur de stockage de MongoDB est optimis√© pour les sch√©mas d'acc√®s al√©atoires (typiques de l'OLTP) plut√¥t que pour les analyses s√©quentielles courantes dans les charges de travail analytiques.

## [EXERCICE] questionner un LLM

**Sc√©nario** : si vous transf√©rez la charge de travail des jointures et de l'agr√©gation au niveau de la collection (par le biais de t√¢ches d'arri√®re-plan r√©guli√®res par exemple), alors un magasin de documents tel que MongoDB devient-il comp√©titif pour les applications OLAP.

- Demander a un LLM (chatGPT, DeepSeek, Claude.ai, Qwen, Mistral, ) ce qu'il en pense.
- Comparer les reponses 2 a 2
- quels sont les arguments avanc√©s

### Morale de l'histoire

Cette phrase met en lumi√®re quand utiliser NoSQL

extrait de : https://softwareengineering.stackexchange.com/a/355964/440337

> _NOSQL est tr√®s largement con√ßu comme une couche de persistance pour une application._
> _L'acc√®s est donc optimis√© pour un seul objet avec des enfants._

en VO

> _NOSQL is very much designed as a persistence layer for an application_
> _So access is optimized for a single object with children._



Beaucoup de choses √† d√©cortiquer ici :

- **couche de persistance** fait r√©f√©rence au stockage et √† la r√©cup√©ration de donn√©es afin qu'elles survivent au-del√† de la dur√©e d'ex√©cution de l'application.

Les bases de donn√©es NoSQL (Document) sont construites sp√©cifiquement pour r√©pondre aux besoins de **stockage de donn√©es** des applications. Le mot important √©tant "Application". Les bases de donn√©es SQL sont con√ßues pour l'organisation et les relations de donn√©es, mais les besoins des applications √©tant secondaires.

Un **seul objet** fait r√©f√©rence √† une entit√© de donn√©es principale (comme un profil d'utilisateur, un produit, une playlist ou un workout)

Les children ou **enfants** font r√©f√©rence aux donn√©es associ√©es qui appartiennent ou sont √©troitement associ√©es √† cet objet principal (comme les adresses d'un utilisateur, les avis sur un produit ou les exercices d'un workout)

Pourquoi est-ce optimis√© pour un  _objet unique_ avec des _enfants_ ?

**unique** est un mot important ici :


Les bases de donn√©es NoSQL stockent physiquement l'objet principal et ses sous d√©pendants ensemble dans un **emplacement unique** sur le disque. Au lieu de diviser les donn√©es associ√©es sur plusieurs tables comme dans les bases de donn√©es relationnelles.

La r√©cup√©ration de toutes les donn√©es associ√©es n√©cessite moins d'op√©rations sur le disque et est moins gourmande en ressources et donc plus rapide.

Ce qui implique √©galement un principe architectural cl√© : les bases de donn√©es NoSQL sont con√ßues autour des mani√®res sp√©cifiques dont les applications ont besoin d'acc√©der et de manipuler les donn√©es, plut√¥t que de maintenir des relations formelles de donn√©es .

Besoin de l'application > Organisation structur√©e des donn√©es

Cela les rend particuli√®rement efficaces lorsqu'une application a besoin de rapidement r√©cup√©rer / mettre √† jour  un objet entier avec toutes ses donn√©es associ√©es et ceci en une seule op√©ration.


[TODO] r√©capituler

### Baisse de Performance

Plusieurs facteurs techniques peuvent affecter les performances :

- **Indexation :** Tout d'abord, les bases de donn√©es NoSQL ne maintiennent pas le m√™me type d'index sophistiqu√©s que les bases de donn√©es relationnelles pour joindre les donn√©es r√©parties dans diff√©rentes collections. Le r√¥le des index dans MongoDB est d'aider √† localiser des documents individuels plutot que d'optimiser les requ√™tes complexes sur plusieurs documents.

- **Acc√®s disque :** DeuxiEnsuite√®mement, lorsque vous devez acc√©der √† plusieurs objets qui ne sont pas physiquement stock√©s √† proximit√© les uns des autres, la base de donn√©es doit effectuer plusieurs recherches al√©atoires sur le disque.

Ces recherches al√©atoires sont beaucoup plus lentes que les lectures s√©quentielles, car la t√™te de lecture du disque doit se d√©placer physiquement vers diff√©rents emplacements. C'est pourquoi les op√©rations qui n√©cessitent l'analyse de nombreux documents (comme les requ√™tes analytiques) peuvent √™tre plus lentes dans MongoDB que dans les bases de donn√©es relationnelles.

- **Gestion de la m√©moire :** Enfin, la gestion de la m√©moire de MongoDB est optimis√©e autour du concept d'ensembles de travail (working sets) :  les documents qui sont le plus fr√©quemment consult√©s. Sur de grands volumes de donn√©es qui d√©passent la taille de la RAM, MongoDB doit constamment √©changer des documents en dedans et en dehors de la m√©moire avec  un impact probable sur les performances.

Sur le point 2, d'Acc√®s disque : Le probl√®me de donn√©es r√©parties un peu partout sur le disque physique √† des emplacements al√©atoires est vrai pour toutes les bases de donn√©es.

Mais PostgreSQL (par exemple) est beaucoup plus optimis√© pour ce genre de t√¢ches que ne l'est MongoDB.

Il existe des diff√©rences architecturales cl√©s dans la mani√®re dont les deux bases de donn√©es g√®rent les op√©rations multi-enregistrements :

- Disposition du stockage : meilleure organisation du stockage et plus de contraintes dans PostgreSQL

  - PostgreSQL stocke les donn√©es dans des tables avec des sch√©mas fixes, en utilisant un concept appel√© "fichiers heap" o√π les enregistrements sont stock√©s dans des blocs/pages. Ces pages sont con√ßues pour un balayage s√©quentiel efficace.

  - MongoDB stocke chaque document ind√©pendamment, potentiellement avec des tailles et des sch√©mas variables. Cela peut conduire √† plus de fragmentation et √† un acc√®s s√©quentiel moins efficace.

- M√©thodes d'acc√®s aux donn√©es : meilleure planification des requ√™tes

  - PostgreSQL a une planification de requ√™tes tr√®s sophistiqu√©e  et donc tr√®s efficace qui choisi entre plusieurs m√©thodes d'acc√®s :
    - Des analyses s√©quentielles (Sequential scans) qui lisent les pages efficacement dans l'ordre
    - Des analyses d'index (Index scans) qui peuvent utiliser plusieurs index simultan√©ment
    - Des analyses bitmap (Bitmap scans) qui peuvent combiner les r√©sultats de plusieurs type d'index
  - MongoDB s'appuie principalement sur des analyses d'index unique (single-index scans) ou des analyses de collection (collection scans), avec moins de facult√©es pour combiner les m√©thodes d'acc√®s

- Op√©rations de jointure :
  - PostgreSQL dispose d'algorithmes sp√©cialis√©s (jointures hach√©es, jointures par fusion, boucles imbriqu√©es) - (hash joins, merge joins, nested loops) - qui sont optimis√©s pour combiner efficacement les donn√©es de plusieurs tables
  - MongoDB doit effectuer des recherches un document √† la fois lors de la combinaison de donn√©es entre les collections, ce qui signifie souvent plus d'E/S al√©atoires

- Gestion des buffers :
  - Le gestionnaire de buffer de PostgreSQL est con√ßu pour optimiser les sch√©mas d'acc√®s s√©quentiels et al√©atoires
  - Le moteur de stockage WiredTiger de MongoDB est principalement optimis√© pour les sch√©mas d'acc√®s al√©atoires

Ainsi, bien que les deux bases de donn√©es doivent effectuer des op√©rations sur disque, PostgreSQL inclut des optimisations sp√©cifiques pour g√©rer efficacement les op√©rations multi-enregistrements, en particulier lorsqu'il s'agit de jointures et d'analyses de grandes tables.

Ces optimisations sont moins pr√©sentes dans MongoDB car son architecture donne la priorit√© aux op√©rations sur un seul document.

### Conclusion sur SQL vs NoSQL - PostgreSQL vs MongoDB

**Impossible d'√©chapper √† la complexit√©.**

La vitesse n'est pas le seul facteur √† prendre en compte lors du choix d'une base de donn√©es.

Ind√©pendamment de toute consid√©ration technique, la disponibilit√© et la productivit√© des ing√©nieurs ont plus d'impact sur les co√ªts que quelques millisecondes gagn√©es sur une requete.

Ce qui motive l'adoption de MongoDB par rapport √† PostgreSQL est

- Comment l'application consomme les donn√©es
- le stockage et la r√©cup√©ration d'enregistrements uniques
- la complexit√© des donn√©es

## Performance

### Comparaison des performances PostgreSQL vs MongoDB

Lisez cet article <https://medium.com/@vosarat1995/postgres-vs-mongo-performance-comparison-for-semi-structured-data-9a5ec6486cf6>

L'auteur cr√©e un grand jeux de donn√©es et teste les performances de MongoDB et de PostgreSQL.

```bash
| Test                                          | Mongo     | PostgreSQL |
| --------------------------------------------- | --------- | ---------- |
| Cr√©ation d'index sur une base de donn√©es vide | 152.9 ms  | 402.0 ms   |
| Insertion par lot                             | 53.50 ms  | 219.15 ms  |
| Insertion un par un                           | 319.3 ms  | 641.9 ms   |
| Lecture de plusieurs enregistrements          | 21.83 ms  | 66.63 ms   |
| Cr√©ation d'index sur 1000 rows                | 1.563 s   | 1.916 s    |
| Requ√™te Complexe                              | 174.51 ms | 60.43 ms   |
```

MongoDB gagne la plupart du temps.

Mais PostgreSQL gagne au sprint final!

De plus : "_It is worth noting that the tests were on semi-structured data which is the realm of Mongo._"

### Explication de la planification des requ√™tes dans MongoDB

Sans entrer pour l'instant dans les d√©tails de creation des index avec MongoDB analysons la planification des requ√™tes.

Pour `EXPLAIN` une requ√™te:

- requ√™te directe : `db.movies.find(<query predicate>).explain("executionStats")`
- pipelines d'agr√©gation : `db.movies.explain("executionStats").aggregate(<the_pipeline>)`

Notez les √©l√©ments suivants

- `totalDocsExamined`
- `nReturned`
- `executionTimeMillisEstimate` : estime le temps d'ex√©cution cumulatif pour le pipeline jusqu'√† l'√©tape en question incluse.
- `rejectedPlans`
- `stage` : COLLSCAN, IXSCAN

comparez : `db.movies.find({ "title": "The Perils of Pauline" }).explain("executionStats")`

Ensuite, cr√©ez un index `db.movies.createIndex({ title: 1 })`

√† nouveau `db.movies.find({ "title": "The Perils of Pauline" }).explain("executionStats")`

Supprimez l'index `db.movies.dropIndex({title : 1})`

Expliquez un pipeline d'agr√©gation `db.movies.explain("executionStats").aggregate([ { $group: { _id: "$genres", averageRating: { $avg: "$imdb.rating" } } }] )`

### Comparaison de la planification des requ√™tes avec PostgreSQL

Consid√©rez un sc√©nario de requ√™tes similaires qui implique de joindre/relier des donn√©es et d'agr√©ger des r√©sultats.

**Requ√™te** : _trouver tous les films des ann√©es 1990 avec leurs r√©alisateurs, regroup√©s par r√©alisateur avec les notes moyennes._

Tout d'abord, MongoDB :

```bash
db.movies.aggregate([
  { $match: {
      year: { $gte: 1990, $lt: 2000 }
  }},
  { $unwind: "$directors" },
  { $group: {
      _id: "$directors",
      avgRating: { $avg: "$imdb.rating" },
      movieCount: { $sum: 1 }
  }}
]).explain("executionStats")
```


Le plan est:

```json
{
  "stages": [
    {
      "$cursor": {
        "queryPlanner": {
          "plannerVersion": 1,
          "namespace": "sample_mflix.movies",
          "indexFilterSet": false,
          "parsedQuery": {
            "year": { "$gte": 1990, "$lt": 2000 }
          },
          "winningPlan": {
            "stage": "COLLSCAN",  // Analyse compl√®te de la collection
            "filter": { "year": { "$gte": 1990, "$lt": 2000 } }
          },
          "rejectedPlans": []
        }
      }
    },
    { "$unwind": "$directors" },  // Op√©ration gourmande en m√©moire
    {
      "$group": {
        "_id": "$directors",
        "avgRating": { "$avg": "$imdb.rating" },
        "movieCount": { "$sum": 1 }
      }
    }
  ]
}
```

Maintenant, l'√©quivalent en PostgreSQL (en supposant un sch√©ma normalis√©) :

```sql
EXPLAIN ANALYZE
SELECT d.name as director,
  AVG(m.rating) as avg_rating,
  COUNT(*) as movie_count
FROM movies m
JOIN movie_directors md ON m.id = md.movie_id
JOIN directors d ON md.director_id = d.id
WHERE m.year >= 1990 AND m.year < 2000
GROUP BY d.name;
```

Ce qui donne :

```bash
QUERY PLAN
------------------------------------------------------------
HashAggregate  (cost=245.97..247.97 rows=200)
  Group Key: d.name
  ->  Hash Join  (cost=121.67..237.42 rows=1710)
        Hash Cond: (md.director_id = d.id)
        ->  Hash Join  (cost=66.50..164.42 rows=1710)
              Hash Cond: (md.movie_id = m.id)
              ->  Seq Scan on movie_directors md
              ->  Hash  (cost=58.00..58.00 rows=680)
                    ->  Index Scan using movies_year_idx on movies m
                          Index Cond: (year >= 1990 AND year < 2000)
        ->  Hash  (cost=40.50..40.50 rows=1173)
              ->  Seq Scan on directors d
```

Les principales diff√©rences dans la planification des requ√™tes sont :

1. Gestion des jointures¬†:
   - PostgreSQL utilise des **jointures hach√©es** (**hash joins**) pour combiner efficacement les donn√©es de plusieurs tables
   - MongoDB doit `$unwind` le tableau imbriqu√© des r√©alisateurs, ce qui cr√©e plusieurs documents en m√©moire

2. Utilisation de l'index¬†:
   - PostgreSQL peut utiliser **plusieurs index** simultan√©ment et choisir diff√©rentes strat√©gies de jointure
   - MongoDB s'appuie g√©n√©ralement sur un seul index par √©tape de l'agr√©gation

3. Gestion de la m√©moire¬†:
   - Les jointures hach√©es de PostgreSQL cr√©ent des tables de hash en m√©moire avec repli  disque si n√©cessaire
   - Les √©tapes `$unwind` et `$group` de MongoDB doivent conserver leurs donn√©es en m√©moire

4. Ordre des op√©rations¬†:
   - Le planificateur de requ√™tes de PostgreSQL peut **r√©organiser les op√©rations** pour plus d'efficacit√©
   - MongoDB doit traiter les √©tapes du pipeline d'agr√©gation dans l'ordre

5. Utilisation des statistiques¬†:
   - L'explication de PostgreSQL montre des estimations de co√ªt d√©taill√©es bas√©es sur les statistiques de la table
   - L'explication de MongoDB se concentre davantage sur le type d'op√©ration et l'utilisation de l'index

Le plan PostgreSQL montre qu'il peut¬†:

- Utiliser une analyse d'index pour le filtre d'ann√©e
- Cr√©er des tables de hachage pour une jointure efficace
- Effectuer un regroupement avec agr√©gation hach√©e
- Estimer les co√ªts et le nombre de lignes √† chaque √©tape

üëΩüëΩüëΩ Cette approche structur√©e des requ√™tes complexes est la raison pour laquelle PostgreSQL est souvent plus performant pour les charges de travail analytiques impliquant plusieurs tables/collections et agr√©gations.


